{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Wishlist Webscraper\n",
    "\n",
    "The following code searches through Amazon wishlists and retrives item names, prices and categories. Unfortunately, Amazon does not allow their data to be distributed so this code is only for personal use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, I collected the top ten names for each decade from the US social security web page. We will read them in and use them to search the Amazon lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sarah', 'Charles', 'Heather', 'Thomas', 'Richard', 'Robert', 'Patricia', 'Abigail', 'Megan', 'Brian', 'Matthew', 'Melissa', 'Joseph', 'Ethan', 'Linda', 'Ashley', 'Nicholas', 'Mary', 'Deborah', 'Amy', 'Jeffrey', 'John', 'Elizabeth', 'Donna', 'Hannah', 'Samantha', 'Andrew', 'William', 'Olivia', 'Jacob', 'Christopher', 'Michelle', 'Isabella', 'Emma', 'Susan', 'James', 'Michael', 'Brittany', 'David', 'Stephanie', 'Angela', 'Nancy', 'Lisa', 'Barbara', 'Mark', 'Amanda', 'Jessica', 'Joshua', 'Madison', 'Taylor', 'Jason', 'Kimberly', 'Debra', 'Cynthia', 'Jennifer', 'Tyler', 'Karen', 'Daniel', 'Nicole', 'Emily']\n"
     ]
    }
   ],
   "source": [
    "topNames = set()\n",
    "\n",
    "#Open the top names file and parse\n",
    "file = open('topNames.txt')\n",
    "lines = [l.split() for l in file.readlines()]\n",
    "\n",
    "#Handpicked indices for each line\n",
    "#based on file\n",
    "for l in lines:\n",
    "    topNames.add(l[1])\n",
    "    topNames.add(l[3])\n",
    "\n",
    "topNames = list(topNames)\n",
    "print(topNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By changing the swapping out the names in the wishlist lookup URL we can find pages of random people and their wishlists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.amazon.com/gp/registry/search/ref=cm_wl_search__sortbar_page_2?ie=UTF8&field-firstname=&field-lastname=&field-name=Robert&index=us-xml-wishlist&page=2&submit.search=1\n"
     ]
    }
   ],
   "source": [
    "#The url for searching wish lists\n",
    "wishlistSearch = 'https://www.amazon.com/gp/registry/search/'\n",
    "siteVar = 'ref=cm_wl_search__sortbar_page_2?ie=UTF8&field-firstname=&field-lastname=&'\n",
    "changeVar = 'field-name={}&index=us-xml-wishlist&page={}&submit.search=1'\n",
    "\n",
    "#Put together the pieces:\n",
    "searchPage = wishlistSearch+siteVar+changeVar.format(topNames[5],2)\n",
    "print(searchPage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above url works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for scraping each portion\n",
    "\n",
    "** 1. Find a bunch of random people **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseSearchResults(searchPage,browser):\n",
    "    #Open the search page\n",
    "    browser.get(searchPage)\n",
    "    searchResultsHTML = browser.page_source\n",
    "    soup = BeautifulSoup(searchResultsHTML,'html.parser')\n",
    "    \n",
    "    #Create an empty dictionary\n",
    "    namesUrls = {'Name':[],'Place':[],'userUrls':[]}\n",
    "    \n",
    "    #Find the first wishlist box\n",
    "    name_box = soup.find('div', attrs={'class':\n",
    "\"a-box a-spacing-top-medium a-color-base-background a-text-left people-box\"})\n",
    "    \n",
    "    while name_box:\n",
    "        #Get the name and user url\n",
    "        textSection = name_box.find('div',attrs={'class':\n",
    "                 'a-section a-spacing-none a-spacing-top-none'})\n",
    "        namesUrls['userUrls'].append(textSection.find('a').get('href'))\n",
    "        namesUrls['Name'].append(textSection.find('a').text.strip())\n",
    "\n",
    "\n",
    "        #If displayed, get where the user is from\n",
    "        item1 = None\n",
    "        item2 = None\n",
    "        \n",
    "        textSection = textSection.find_next_sibling()\n",
    "        if textSection:\n",
    "            item1 = textSection.text\n",
    "            textSection = textSection.find_next_sibling()\n",
    "            if textSection:\n",
    "                item2 = textSection.text\n",
    "\n",
    "        #Check which item is a birthday and which is a place\n",
    "        if item1 and item2:\n",
    "            place = item2.strip()\n",
    "        else:\n",
    "            try: \n",
    "                int(item1.strip()[-1])\n",
    "                place = None\n",
    "            except ValueError:\n",
    "                place = item1.strip()\n",
    "            except TypeError:\n",
    "                place = None\n",
    "            except AttributeError:\n",
    "                place = None\n",
    "                \n",
    "        namesUrls['Place'].append(place)\n",
    "        \n",
    "        #Iterate\n",
    "        name_box = name_box.find_next_sibling()\n",
    "    \n",
    "    #Rest\n",
    "    time.sleep(1)\n",
    "    \n",
    "    return namesUrls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2. Get people's wishlists **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findWishlistUrls(userUrl,browser):\n",
    "    \"\"\"Parses the user list page and returns\n",
    "    the wish lists urls\n",
    "    \"\"\"\n",
    "    #To store wishlist urls\n",
    "    wishlists = []\n",
    "    \n",
    "    try:\n",
    "        browser.get(userUrl)\n",
    "        userPageHTML = browser.page_source\n",
    "        soup = BeautifulSoup(userPageHTML,'html.parser')\n",
    "        listsBox = soup.find('div', attrs={'id':'my-lists-tab'})\n",
    "        if listsBox:\n",
    "            listsBox = listsBox.find('div',attrs={\"aria-expanded\":\"true\"})\n",
    "            for l in listsBox.findAll('a'): \n",
    "                wishlists.append(str(l.get('href')))\n",
    "        \n",
    "    except TimeoutException:\n",
    "        pass\n",
    "    \n",
    "    #Rest\n",
    "    time.sleep(1)\n",
    "    \n",
    "    return wishlists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.Get all the items in each wishlist **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseWishlist(wishlistUrl,browser):\n",
    "    allItems = {\n",
    "        'Name':[],\n",
    "        'Price':[],\n",
    "        'Url':[]\n",
    "    }\n",
    "    try:\n",
    "        browser.get(wishlistUrl)\n",
    "        time.sleep(3)\n",
    "        #Scroll to the bottom of page with arbitarily large number\n",
    "        browser.execute_script(\"window.scrollTo(0,10000000)\")\n",
    "        time.sleep(3)\n",
    "        \n",
    "    except TimeoutException:\n",
    "        pass\n",
    "    \n",
    "    #Seach through the HTML for the data\n",
    "    listPageHTML = browser.page_source\n",
    "    soup = BeautifulSoup(listPageHTML,'html.parser')\n",
    "\n",
    "    gifts = soup.find('ul', attrs={'id':'g-items'})\n",
    "    try:\n",
    "        item = gifts.find('li')\n",
    "\n",
    "        while item:\n",
    "            #Find the name and url\n",
    "            nameLink = item.find('a', attrs={'class':'a-link-normal'})\n",
    "\n",
    "            #Store the data\n",
    "            if nameLink:\n",
    "                allItems['Name'].append(nameLink.get('title'))\n",
    "                allItems['Url'].append(nameLink.get('href'))\n",
    "                allItems['Price'].append(item.get('data-price'))\n",
    "\n",
    "            #iterate\n",
    "            item = item.find_next('li',attrs={'class':'a-spacing-none g-item-sortable'})\n",
    "\n",
    "    except AttributeError:\n",
    "        return None\n",
    "    \n",
    "    return allItems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Get the item category for each item**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCategory(itemUrl,browser):\n",
    "    #Find the category\n",
    "    try:\n",
    "        browser.get(itemUrl)\n",
    "        soup = BeautifulSoup(browser.page_source,'html.parser')\n",
    "    except TimeoutException:\n",
    "        return ''\n",
    "    \n",
    "    breadcrumb = soup.find('div',attrs={'id':'wayfinding-breadcrumbs_container'})\n",
    "    \n",
    "    if breadcrumb:\n",
    "        #Process Strings\n",
    "        category = breadcrumb.text\n",
    "        category = category.split('\\n')\n",
    "        category = [c.strip() for c in category]\n",
    "        category = ', '.join(category)\n",
    "        return category\n",
    "    \n",
    "    else:\n",
    "        return ''\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Browser Object\n",
    "browser = webdriver.Chrome()\n",
    "\n",
    "#Urls\n",
    "amazon = 'https://www.amazon.com'\n",
    "wishlistSearch = amazon + '/gp/registry/search/ref=cm_wl_search__\\\n",
    "sortbar_page_2?ie=UTF8&field-firstname=&field-lastname=&'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store the data in an SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a sql database to store data\n",
    "\n",
    "db = sqlite3.connect(\"amazonData.SQL\")\n",
    "cur = db.cursor()\n",
    "\n",
    "#Create tables to store data\n",
    "#cur.execute(\"\"\"DROP TABLE IF EXISTS people \"\"\")\n",
    "#cur.execute(\"\"\"DROP TABLE IF EXISTS wishlists \"\"\")\n",
    "#cur.execute(\"\"\"DROP TABLE IF EXISTS items \"\"\")\n",
    "\n",
    "#cur.execute(\"\"\"CREATE TABLE people (ID TEXT, Name TEXT,Place TEXT,userUrls TEXT)\"\"\")\n",
    "#cur.execute(\"\"\"CREATE TABLE wishlists (ID TEXT, wishlistUrl TEXT)\"\"\")\n",
    "#cur.execute(\"\"\"CREATE TABLE items (ID TEXT, Name TEXT, Price FLOAT, Url TEXT, Category TEXT)\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Execute Function 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Browser Object\n",
    "browser = webdriver.Chrome()\n",
    "\n",
    "#Urls\n",
    "amazon = 'https://www.amazon.com'\n",
    "wishlistSearch = amazon + '/gp/registry/search/ref=cm_wl_search__\\\n",
    "sortbar_page_2?ie=UTF8&field-firstname=&field-lastname=&'\n",
    "\n",
    "#Static Variable\n",
    "nextID = 1\n",
    "\n",
    "#Urls with variables to edit\n",
    "changeVar = 'field-name={}&index=us-xml-wishlist&page={}&submit.search=1'\n",
    "\n",
    "#Loop through five random pages of search results for each name\n",
    "for commonName in topNames:\n",
    "    for pageNum in np.random.randint(40,size=5):\n",
    "        searchPage = wishlistSearch+changeVar.format(commonName,pageNum)\n",
    "        peopleInfo = parseSearchResults(searchPage,browser)\n",
    "        \n",
    "        #Create ID numbers\n",
    "        numUsers = len(peopleInfo['Name'])\n",
    "        ID = [str(id) for id in range(nextID,nextID+numUsers)]\n",
    "        nextID += numUsers + 1\n",
    "\n",
    "        #Store User Data\n",
    "        peopleInfo['userUrls'] = [amazon+url for url in peopleInfo['userUrls']]\n",
    "        peopleTuple = zip(ID,peopleInfo['Name'],\n",
    "                            peopleInfo['Place'],\n",
    "                            peopleInfo['userUrls'])\n",
    "        cur.executemany(\"INSERT INTO people VALUES(?,?,?,?)\",peopleTuple)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Execute Function 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through each user and find all wishlists\n",
    "cur.execute(\"SELECT ID, userUrls FROM people\")\n",
    "\n",
    "for  idUrl in cur.fetchall():\n",
    "    #Scrape Data\n",
    "    ID,userUrl = idUrl\n",
    "    wishlists = findWishlistUrls(userUrl,browser)\n",
    "    \n",
    "    #Store Data\n",
    "    wishlists = [amazon+wl for wl in wishlists]\n",
    "    wlTuple = zip([ID]*len(wishlists),wishlists)\n",
    "    cur.executemany(\"INSERT INTO wishlists VALUES(?,?)\",wlTuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Execute Function 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through each wishlist to find all items\n",
    "cur.execute(\"SELECT ID, wishlistUrl FROM wishlists\")\n",
    "\n",
    "for idUrl in cur.fetchall():\n",
    "    #Scrape data\n",
    "    ID,wlUrl = idUrl\n",
    "    items = parseWishlist(wlUrl,browser)\n",
    "    \n",
    "    #Store Data\n",
    "    if items:\n",
    "        items['Url'] = [amazon + url for url in items['Url']]\n",
    "        itemTuple = zip([ID]*len(items['Price']),\n",
    "                       items['Name'],\n",
    "                       items['Price'],\n",
    "                       items['Url'])\n",
    "        cur.executemany(\"INSERT INTO items VALUES(?,?,?,?)\",itemTuple)\n",
    "\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Execute Function 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=67.0.3396.79)\n  (Driver info: chromedriver=2.38.552518 (183d19265345f54ce39cbb94cf81ba5f15905011),platform=Mac OS X 10.12.3 x86_64)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-926fa627ddd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetCategory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbrowser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-05939aa153b9>\u001b[0m in \u001b[0;36mgetCategory\u001b[0;34m(itemUrl, browser)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitemUrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/anaconda/lib/python2.7/site-packages/selenium/webdriver/remote/webdriver.pyc\u001b[0m in \u001b[0;36mpage_source\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    670\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \"\"\"\n\u001b[0;32m--> 672\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_PAGE_SOURCE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/anaconda/lib/python2.7/site-packages/selenium/webdriver/remote/webdriver.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    316\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m/Library/Python/anaconda/lib/python2.7/site-packages/selenium/webdriver/remote/errorhandler.pyc\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=67.0.3396.79)\n  (Driver info: chromedriver=2.38.552518 (183d19265345f54ce39cbb94cf81ba5f15905011),platform=Mac OS X 10.12.3 x86_64)\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT Url, Name FROM items\")\n",
    "items = cur.fetchall()\n",
    "Categories = []\n",
    "\n",
    "for it in items:\n",
    "    url,Name = it\n",
    "    cat = getCategory(url,browser)\n",
    "    \n",
    "    \n",
    "    cur.execute('''\\\n",
    "    UPDATE items\\\n",
    "    SET Category=?\n",
    "    WHERE Name = ?;\n",
    "    ''',(cat,Name))\n",
    "    \n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon started captcha blocking me, but not before I got 14464 item categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x10650aa40>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"Select Category from items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u', , , , , Clothing, Shoes & Jewelry, , , , \\u203a, , , , Women, , , , \\u203a, , , , Clothing, , , , \\u203a, , , , Tops & Tees, , , , \\u203a, , , , Knits & Tees, , , , , ',),\n",
       " (u', , , , , Clothing, Shoes & Jewelry, , , , \\u203a, , , , Women, , , , \\u203a, , , , Clothing, , , , \\u203a, , , , Tops & Tees, , , , \\u203a, , , , Blouses & Button-Down Shirts, , , , , ',),\n",
       " (u', , , , , Clothing, Shoes & Jewelry, , , , \\u203a, , , , Women, , , , \\u203a, , , , Clothing, , , , \\u203a, , , , Tops & Tees, , , , \\u203a, , , , Vests, , , , , ',),\n",
       " (u', , , , , Clothing, Shoes & Jewelry, , , , \\u203a, , , , Women, , , , \\u203a, , , , Clothing, , , , \\u203a, , , , Tops & Tees, , , , \\u203a, , , , Blouses & Button-Down Shirts, , , , , ',),\n",
       " (u', , , , , Clothing, Shoes & Jewelry, , , , \\u203a, , , , Women, , , , \\u203a, , , , Clothing, , , , \\u203a, , , , Tops & Tees, , , , \\u203a, , , , Blouses & Button-Down Shirts, , , , , ',)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = cur.fetchall()\n",
    "cat[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u', , , , , Beauty & Personal Care, , , , \\u203a, , , , Hair Care, , , , \\u203a, , , , Styling Tools & Appliances, , , , \\u203a, , , , Hot-Air Brushes, , , , , ',)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat[14564]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227640"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [anaconda]",
   "language": "python",
   "name": "Python [anaconda]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
